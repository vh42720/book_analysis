{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 01 - Cleaning the datasets\n",
    "\n",
    "This notebook outlines the cleaning process of multiple dataset involving book\n",
    "sales and rating so it can be used for EDA and analysis later on.\n",
    "Fortunately, most of the datasets are clearly label and preprocessed.\n",
    "The main objectives would be replacing/removing missing values and joining\n",
    "necessary tables.\n",
    "\n",
    "The 4 datasets are as followed:\n",
    "\n",
    "1. [publishers](https://corgis-edu.github.io/corgis/csv/publishers/)\n",
    "    * Ebook sales data from Amazon for 27k titles in 2015\n",
    "2. [BX-Book-Rating](http://www2.informatik.uni-freiburg.de/~cziegler/BX/)\n",
    "    * Rating info on over 270k titles\n",
    "3. [BX-Books](http://www2.informatik.uni-freiburg.de/~cziegler/BX/)\n",
    "    * Books info on over 270k title above. Lacking isbn!\n",
    "4. [goodreads](https://www.kaggle.com/jealousleopard/goodreadsbooks#books.csv)\n",
    "    * Goodreads book dataset including rating and reviews\n",
    "\n",
    "After cleaning, there will be 3 datasets with label for specific use:\n",
    "1. book_sales: contains ebook sales data.\n",
    "2. book_goodreads: contains books info pulled from good reads.\n",
    "3. book_rating: contains book rating from multiple sources."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## book_sales data\n",
    "\n",
    "Steps:\n",
    "1. Lower column name case and change to snake cases.\n",
    "2. Since multiple sales metrics are recorded, keep only the\n",
    "unit sales column to ensure linearity.\n",
    "3. Adding price_range column for eda. Based on Amazon ebook price range\n",
    "4 ranges are:cheap ()\n",
    "       a) cheap: 0 - 2.99\n",
    "       b) normal: 2.99 - 9.99\n",
    "       c) high: 9.99 - 19.99\n",
    "       d) extra: 19.99+"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27027 entries, 0 to 27026\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype   \n",
      "---  ------                    --------------  -----   \n",
      " 0   genre                     27027 non-null  object  \n",
      " 1   sold_by                   27027 non-null  object  \n",
      " 2   daily_average_units_sold  27027 non-null  int64   \n",
      " 3   publisher_name            27027 non-null  object  \n",
      " 4   publisher_type            27027 non-null  object  \n",
      " 5   average_rating            27027 non-null  float64 \n",
      " 6   sale_price                27027 non-null  float64 \n",
      " 7   total_reviews             27027 non-null  int64   \n",
      " 8   price_range               27027 non-null  category\n",
      "dtypes: category(1), float64(2), int64(2), object(4)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Loading Publisher dataset\n",
    "data_path = 'D:\\\\PycharmProjects\\\\springboard\\\\data\\\\'\n",
    "sales = pd.read_csv(f'{data_path}publishers.csv')\n",
    "\n",
    "# Replace dot and space in columns name. Remove the word statistic in column name\n",
    "sales.columns = sales.columns.str.replace(r'[\\.\\s]', '_').str.replace('statistics_', '')\n",
    "\n",
    "# Remove multiple revenues and gross sales columns as these will create Multicollinearity \n",
    "# We only want units_sold in this case\n",
    "sales = sales.drop(sales.columns[2:6], axis=1)\n",
    "sales = sales.drop('sales_rank', axis=1)\n",
    "\n",
    "# Cut prices into range for further analysis\n",
    "sales['price_range'] = pd.cut(sales.sale_price, bins=[0, 2.99,9.99,19.99, max(sales.sale_price)], \n",
    "                           labels=['cheap','normal','high','extra'])\n",
    "\n",
    "# Save the cleaned data with new name\n",
    "sales.to_csv(f'{data_path}book_sales.csv')\n",
    "\n",
    "# Final look at the dataframe\n",
    "sales.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## book_rating data\n",
    "\n",
    "The cleaned dataset will combine BX-Book-Ratings and BX-Books. This is\n",
    "a simple data with just the ratings and the number of ratings.\n",
    "\n",
    "Notes: Before loading the data, there are some anomaly in the book titles that\n",
    "are manually removed (',' conflicting with csv separator).\n",
    "\n",
    "Steps:\n",
    "1. Lowercase the columns and change them to snake case.\n",
    "2. Group the rating by ISBN and calculate the mean. Create the count of\n",
    "rating column afterward.\n",
    "3. Joining two tables by ISBN."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "book_title             271379\nbook_author            271378\nyear_of_publication    271379\npublisher              271377\ndtype: int64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load books data set and clean up column names. Omitted last 3 columns since they are\n",
    "# links only\n",
    "books = pd.read_csv(f'{data_path}BX-Books.csv', sep=';', error_bad_lines=True,\n",
    "                    usecols=[0,1,2,3,4], encoding='ISO-8859-1', index_col='ISBN',\n",
    "                    low_memory=False)\n",
    "books.columns = books.columns.str.lower().str.replace('-','_')\n",
    "\n",
    "# Count\n",
    "books.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are multiples reviews of the same book (isbn) from different users. Thus, we will\n",
    "get the mean rating as the metric to merge into books reviews."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 340556 entries,  0330299891 to Ô½crosoft\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   book_rating   340556 non-null  float64\n",
      " 1   total_rating  340556 non-null  int64  \n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 7.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load reviews data. We also lower case and snake_case column names\n",
    "reviews = pd.read_csv(f'{data_path}BX-Book-Ratings.csv', sep=';', error_bad_lines=True,\n",
    "                      encoding='ISO-8859-1', usecols=[1,2])\n",
    "reviews.columns = reviews.columns.str.lower().str.replace('-', '_')\n",
    "\n",
    "# Group by isbn and get the number of rating\n",
    "total_rating = reviews.groupby('isbn').count()\n",
    "\n",
    "# Group by isbn and get mean rating\n",
    "reviews = reviews.groupby('isbn').mean()\n",
    "reviews['total_rating'] = total_rating\n",
    "\n",
    "# print info on reviews\n",
    "reviews.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 270167 entries, 0195153448 to 0767409752\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   book_title           270167 non-null  object \n",
      " 1   book_author          270167 non-null  object \n",
      " 2   year_of_publication  270167 non-null  object \n",
      " 3   publisher            270167 non-null  object \n",
      " 4   book_rating          270167 non-null  float64\n",
      " 5   total_rating         270167 non-null  float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 14.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Merge books and reviews on isbn. Leave reviews without the isbn\n",
    "rating = pd.merge(books, reviews, how='left', left_index=True, right_index=True)\n",
    "rating = rating.dropna()\n",
    "\n",
    "# save for future use\n",
    "rating.to_csv(f'{data_path}book_rating.csv')\n",
    "\n",
    "# first look\n",
    "rating.info()\n",
    "rating.head()\n",
    "\n",
    "# Clear out unused data frames\n",
    "del books\n",
    "del reviews"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Goodread books data\n",
    "\n",
    "Used for rating prediction\n",
    "\n",
    "There are some problems with a few lines in the dataset that needs correction since they use\n",
    "comma instead of dot-comma in the author name. However, there are less than 5 of these so manual \n",
    "fixing is efficient. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   title  \\\n",
      "8180   In Pursuit of the Proper Sinner (Inspector Lyn...   \n",
      "11098         Montaillou  village occitan de 1294 à 1324   \n",
      "\n",
      "                                               authors  average_rating  \\\n",
      "8180                                 Elizabeth  George            4.10   \n",
      "11098  Emmanuel Le Roy Ladurie/Emmanuel Le Roy-Ladurie            3.96   \n",
      "\n",
      "      language_code  num_pages  ratings_count  text_reviews_count  \\\n",
      "8180            eng        718          10608                 295   \n",
      "11098           fre        640             15                   2   \n",
      "\n",
      "      publication_date       publisher  title_length  \n",
      "8180               NaT    Bantam Books            55  \n",
      "11098              NaT  Folio histoire            42  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11125 entries, 0 to 11126\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   title               11125 non-null  object        \n",
      " 1   authors             11125 non-null  object        \n",
      " 2   average_rating      11125 non-null  float64       \n",
      " 3   language_code       11125 non-null  object        \n",
      " 4   num_pages           11125 non-null  int64         \n",
      " 5   ratings_count       11125 non-null  int64         \n",
      " 6   text_reviews_count  11125 non-null  int64         \n",
      " 7   publication_date    11125 non-null  datetime64[ns]\n",
      " 8   publisher           11125 non-null  object        \n",
      " 9   title_length        11125 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(4), object(4)\n",
      "memory usage: 956.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load in the data\n",
    "goodread_books = pd.read_csv(f'{data_path}goodread_books.csv')\n",
    "\n",
    "# Remove bookID, isbn, isbn13, and publication_date\n",
    "goodread_books = goodread_books.drop(['bookID', 'isbn','isbn13'], axis=1)\n",
    "\n",
    "# remove space from column name\n",
    "goodread_books.columns = goodread_books.columns.str.strip()\n",
    "\n",
    "# Title length\n",
    "goodread_books['title_length'] = goodread_books.title.str.len()\n",
    "\n",
    "# Convert publishing date to datetime\n",
    "goodread_books['publication_date'] = pd.to_datetime(goodread_books.publication_date, errors='coerce')\n",
    "\n",
    "# This two book has a very bad publication date\n",
    "print(goodread_books[goodread_books.publication_date.isnull()])\n",
    "\n",
    "# Remove na \n",
    "goodread_books = goodread_books.dropna()\n",
    "\n",
    "# info\n",
    "goodread_books.info()\n",
    "\n",
    "# Save for later\n",
    "goodread_books.to_csv(f'{data_path}/book_goodread.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}